---
title: \vspace{2in} Estimating Study Heterogeneity 
subtitle: "PHP 2550: Final Project"
author: "Blain Morin"
date: "December 19, 2018"
indent: true
output: 
  pdf_document:
    toc: true
header-includes:
- \usepackage{float}
- \usepackage{indentfirst}
---

&nbsp;


```{r, echo = FALSE, message = FALSE, warning = FALSE}

### Set knitr options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE)

### Load Required Libraries

library(readr)
library(dplyr)
library(ggplot2)
library(extrafont)
library(stargazer)
library(tidyr)
library(metafor)

### set seed
set.seed(100)

### Load Data
full = read_delim("2010_6.csv", "\t", 
                      escape_double = FALSE, trim_ws = TRUE)

```

```{r}

### Exclude studies with .5s
full = full %>%
  filter(a > 1,
         b > 1,
         c > 1,
         d > 1) %>%
  group_by(my_ID) %>%
  mutate(correct_no_of_studies = n()) %>%
  ungroup() %>%
  filter(correct_no_of_studies >= 5) 


### Get only largest meta (highest number of studies)
full = full %>%
  group_by(number_review) %>%
  filter(correct_no_of_studies == max(correct_no_of_studies)) %>%
  mutate(n = a + b + c + d) %>%
  group_by(my_ID) %>%
  mutate(meta.n = sum(n)) %>%
  ungroup() %>%
  group_by(number_review) %>%
  filter(meta.n == max(meta.n)) %>%
  ungroup()


```

```{r}

### Add study effect size and variance
### Add DesSimonian-Laird Estimate for tau2 and se.tau2
full = full %>% 
  mutate(yi = escalc(measure = "OR",
                     ai = a,
                     bi = b,
                     ci = c, 
                     di = d)$yi,
         vi = escalc(measure = "OR",
                     ai = a,
                     bi = b,
                     ci = c, 
                     di = d)$vi) %>%
  group_by(my_ID) %>%
  mutate(DL.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "DL")$tau2,
         DL.se.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "DL")$se.tau2,
         DL.summary = rma.uni(yi = yi,
                           vi = vi,
                           method = "DL")$beta) %>%
  ungroup()
  


```

```{r}

### Add Paule and Mandel 
full = full %>%
  group_by(my_ID) %>%
  mutate(PM.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "PM")$tau2,
         PM.se.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "PM")$se.tau2,
         PM.summary = rma.uni(yi = yi,
                           vi = vi,
                           method = "PM")$beta) %>%
  ungroup()
  

```

```{r}

### Add Hedges 
full = full %>%
  group_by(my_ID) %>%
  mutate(HE.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "HE")$tau2,
         HE.se.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "HE")$se.tau2,
         HE.summary = rma.uni(yi = yi,
                           vi = vi,
                           method = "HE")$beta) %>%
  ungroup()

```

```{r}

### Add Hunter-Schmidt
full = full %>%
  group_by(my_ID) %>%
  mutate(HS.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "HS")$tau2,
         HS.se.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "HS")$se.tau2,
         HS.summary = rma.uni(yi = yi,
                           vi = vi,
                           method = "HS")$beta) %>%
  ungroup()

```

```{r}

### Add Maximum Likelihood
full = full %>%
  group_by(my_ID) %>%
  mutate(ML.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "ML")$tau2,
         ML.se.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "ML")$se.tau2,
         ML.summary = rma.uni(yi = yi,
                           vi = vi,
                           method = "ML")$beta) %>%
  ungroup()

```

```{r}

### Add REML
full = full %>%
  group_by(my_ID) %>%
  mutate(REML.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "REML", control=list(maxiter=1000))$tau2,
         REML.se.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "REML", control=list(maxiter=1000))$se.tau2,
         REML.summary = rma.uni(yi = yi,
                           vi = vi,
                           method = "REML", control=list(maxiter=1000))$beta) %>%
  ungroup()

```

```{r}

### Add Sidik-Jonkman
full = full %>%
  group_by(my_ID) %>%
  mutate(SJ.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "SJ")$tau2,
         SJ.se.tau2 = rma.uni(yi = yi,
                           vi = vi,
                           method = "SJ")$se.tau2,
         SJ.summary = rma.uni(yi = yi,
                           vi = vi,
                           method = "SJ")$beta) %>%
  ungroup()


```


```{r}

### Set plot colors
cols <- c("DerSimonian-Laird" = "green",
          "Hedges" = "yellow",
          "Hunter-Schmidt" = "purple",
          "Sidik-Jonkman" = "blue",
          "Maximum-Likelihood" = "orange",
          "REML" = "black",
          "Paule-Mandel" = "red")


```


```{r}

### 60 Random study tau estimates plot
set.seed(100)

temp = full %>%
  group_by(number_review) %>%
  slice(1) %>%
  ungroup() %>%
  sample_n(size = 60)

tau.estimates.plot = temp %>%
  ggplot(aes(x = review)) +
  geom_point(aes(y = PM.tau2, color = "Paule-Mandel"), shape = 15, size = 3) +
  geom_point(aes(y = DL.tau2, color = "DerSimonian-Laird"), shape = 15, size = 3) +
  geom_point(aes(y = SJ.tau2, color = "Sidik-Jonkman"), shape = 15, size = 3) +
  geom_point(aes(y = HE.tau2, color = "Hedges"), shape = 15, size = 3) +
  geom_point(aes(y = HS.tau2, color = "Hunter-Schmidt"), shape = 15, size = 3) +
  geom_point(aes(y = ML.tau2, color = "Maximum-Likelihood"), shape = 15, size = 3) +
  geom_point(aes(y = REML.tau2, color = "REML"), shape = 15, size = 3) +
  scale_colour_manual(name = "Method:", values = cols) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
  ylab("Tau Squared") +
  xlab("Cochrane Review") +
  theme(text=element_text(size=12,  family="CM Sans"))
  

```

```{r}

### 60 Random study summary estimates plot

summary.estimates.plot = temp %>%
  ggplot(aes(x = review)) +
  geom_point(aes(y = PM.summary, color = "Paule-Mandel"), shape = 15, size = 3, alpha = .6) +
  geom_point(aes(y = DL.summary, color = "DerSimonian-Laird"), shape = 15, size = 3, alpha = .6) +
  geom_point(aes(y = SJ.summary, color = "Sidik-Jonkman"), shape = 15, size = 3, alpha = .6) +
  geom_point(aes(y = HE.summary, color = "Hedges"), shape = 15, size = 3, alpha = .6) +
  geom_point(aes(y = HS.summary, color = "Hunter-Schmidt"), shape = 15, size = 3, alpha = .6) +
  geom_point(aes(y = ML.summary, color = "Maximum-Likelihood"), shape = 15, size = 3, alpha = .6) +
  geom_point(aes(y = REML.summary, color = "REML"), shape = 15, size = 3, alpha = .6) +
  scale_colour_manual(name = "Method:", values = cols) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
  ylab("log(Odds Ratio)") +
  xlab("Cochrane Review") +
  theme(text=element_text(size=12,  family="CM Sans"))


```


```{r}

### Put in long format
full.long = full %>%
  gather(key = "model", value = "summary", DL.summary, PM.summary,
         HE.summary, HS.summary, ML.summary, REML.summary, SJ.summary)

### Slice 1 summary for each model
full.long = full.long %>%
  group_by(my_ID, model) %>%
  slice(1) %>%
  ungroup()

### Calculate biggest difference
full.long = full.long %>%
  group_by(my_ID) %>%
  mutate(abs.sum = abs(summary)) %>%
  mutate(diff = max(abs.sum) - min(abs.sum)) %>%
  mutate(p.diff = diff/max(abs.sum)) %>%
  ungroup()

### Proportionate Difference Plot
p.diff.plot = full.long %>%
  group_by(my_ID) %>%
  slice(1) %>%
  ggplot(aes(x = p.diff)) +
  geom_histogram(binwidth = .1, fill = "white", color = "black") +
  theme_light() +
  scale_x_continuous(breaks = seq(0, 1, .1)) +
  xlab("Proportionate Difference") +
  ylab("Count") +
  theme(text=element_text(size=12,  family="CM Sans"))

```

```{r}

sums = full %>%
  group_by(my_ID) %>%
  slice(1) %>%
  ungroup()

sums1 = sums %>%
  select(DL.tau2, HE.tau2,
         HS.tau2, SJ.tau2,
         ML.tau2, REML.tau2,
         PM.tau2) %>%
  summarise(meanDL = mean(DL.tau2),
            meanHE = mean(HE.tau2),
            meanHS = mean(HS.tau2),
            meanSJ = mean(SJ.tau2),
            meanML = mean(ML.tau2),
            meanREML = mean(REML.tau2),
            meanPM = mean(PM.tau2))

sums2 = sums %>%
  select(DL.tau2, HE.tau2,
         HS.tau2, SJ.tau2,
         ML.tau2, REML.tau2,
         PM.tau2) %>%
  summarise(sdDL = sd(DL.tau2),
            sdHE = sd(HE.tau2),
            sdHS = sd(HS.tau2),
            sdSJ = sd(SJ.tau2),
            sdML = sd(ML.tau2),
            sdREML = sd(REML.tau2),
            sdPM = sd(PM.tau2))

sums3 = sums %>%
  select(DL.tau2, HE.tau2,
         HS.tau2, SJ.tau2,
         ML.tau2, REML.tau2,
         PM.tau2) %>%
  summarise(maxDL = max(DL.tau2),
            maxHE = max(HE.tau2),
            maxHS = max(HS.tau2),
            maxSJ = max(SJ.tau2),
            maxML = max(ML.tau2),
            maxREML = max(REML.tau2),
            maxPM = max(PM.tau2))

sums4 = cbind(t(sums1), t(sums2), t(sums3))

row.names(sums4) = c("DerSimonian-Laird",
                     "Hedges",
                     "Hunter-Schmidt",
                     "Sidik-Jonkman",
                     "Maximum-Likelihood",
                     "REML",
                     "Paule-Mandel")

sums4 = as.data.frame(sums4)

sums4 = sums4 %>%
  rename(Mean.Tau2 = V1, Sd.Tau2 = V2, Max.Tau2 = V3)

```

```{r}

### Tau squared densities

tau.square.density.plot = full %>%
  group_by(my_ID) %>%
  mutate(DL.tau2 = DL.tau2 + .0001,
         HE.tau2 = HE.tau2 + .0001,
         HS.tau2 = HS.tau2 + .0001,
         SJ.tau2 = SJ.tau2 + .0001,
         ML.tau2 = ML.tau2 + .0001,
         REML.tau2 = REML.tau2 + .0001,
         PM.tau2 = PM.tau2 + .0001) %>%
  slice(1) %>%
  ungroup %>%
  ggplot() +
  geom_line(aes(x = log(DL.tau2), color = "DerSimonian-Laird"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(HE.tau2), color = "Hedges"), size = 2, stat = "density", alpha = .6) +
  geom_line(aes(x = log(HS.tau2), color = "Hunter-Schmidt"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(SJ.tau2), color = "Sidik-Jonkman"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(ML.tau2), color = "Maximum-Likelihood"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(REML.tau2), color = "REML"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(PM.tau2), color = "Paule-Mandel"), stat = "density", size = 2, alpha = .6) +
  theme_light() +
  scale_color_manual(name = "Method:", values = cols) +
  ylab("Density") +
  xlab("log(Tau Squared)") 
  
```

```{r}

tau.se.density.plot = full %>%
  group_by(my_ID) %>%
  mutate(DL.tau2 = DL.tau2 + .0001,
         HE.tau2 = HE.tau2 + .0001,
         HS.tau2 = HS.tau2 + .0001,
         SJ.tau2 = SJ.tau2 + .0001,
         ML.tau2 = ML.tau2 + .0001,
         REML.tau2 = REML.tau2 + .0001,
         PM.tau2 = PM.tau2 + .0001) %>%
  slice(1) %>%
  ungroup %>%
  ggplot() +
  geom_line(aes(x = log(DL.se.tau2), color = "DerSimonian-Laird"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(HE.se.tau2), color = "Hedges"), size = 2, stat = "density", alpha = .6) +
  geom_line(aes(x = log(HS.se.tau2), color = "Hunter-Schmidt"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(SJ.se.tau2), color = "Sidik-Jonkman"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(ML.se.tau2), color = "Maximum-Likelihood"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(REML.se.tau2), color = "REML"), stat = "density", size = 2, alpha = .6) +
  geom_line(aes(x = log(PM.se.tau2), color = "Paule-Mandel"), stat = "density", size = 2, alpha = .6) +
  theme_light() +
  scale_color_manual(name = "Method:", values = cols) +
  ylab("Density") +
  xlab("log(Tau Squared SE)") 
  
  
  
  
```

```{r}

# ### Forest plot for highest tau
# high.tau.forest = full %>%
#   filter(my_ID == 39123)
# 
# high.tau.forest2 = rma.uni(measure = "OR", ai = high.tau.forest$a,
#                            bi = high.tau.forest$b,
#                            ci = high.tau.forest$c, 
#                            di = high.tau.forest$d, 
#                            slab = high.tau.forest$study)
# 
# forest(high.tau.forest2, ilab = high.tau.forest$n, ilab.xpos = -6)
# text(c(-6), 12, c("n"))
# title("Forest Plot for CD005089")

```

```{r}

n.studies.hist = full %>%
  group_by(number_review) %>%
  slice(1) %>%
  ungroup() %>%
  filter(correct_no_of_studies < 75) %>%
  ggplot(aes(x = correct_no_of_studies)) +
  geom_histogram(binwidth = 5, color = "black", fill = "white") +
  theme_light() +
  scale_color_manual(name = "Method:", values = cols) +
  ylab("Count") +
  xlab("Number of Studies in the Meta-Analysis") +
  theme(text=element_text(size=12,  family="CM Sans")) +
  scale_x_continuous(breaks = seq(0, 75, 5))


```


```{r}

meta.n.density.plot = full %>%
  group_by(number_review) %>%
  slice(1) %>%
  ungroup() %>%
  filter(meta.n < 50000) %>%
  ggplot(aes(x = meta.n)) +
  geom_density(color = "black", fill = "white") +
  theme_light() +
  scale_color_manual(name = "Method:", values = cols) +
  ylab("Count") +
  xlab("Meta Sample Size")  +
  theme(text=element_text(size=12,  family="CM Sans"))

```

\newpage

# Introduction

  Meta-analysis is the statistical method for analyzing data that comes from a synthesis of studies. It is often a key component of a systematic review. The aim is to summarize all of the available evidence in response to a research question. After identifying and screening all of the relevant studies, their data are extracted and meta-analytic techniques are used to quantitatively assess the evidence. Such analyses guide new research and allow their users to make fully informed and scientifically rigorous decisions.
  
&nbsp;
  
  Here is a simple example of an evidence synthesis:
  
```{r}

### Random Forest Plot

random.meta = full %>%
  filter(my_ID == 6013)

random.meta2 = rma.uni(measure = "OR", ai = random.meta$a,
                           bi = random.meta$b,
                           ci = random.meta$c,
                           di = random.meta$d,
                           slab = random.meta$study,
                       method = "FE")
par(family = 'CM Sans')
forest(random.meta2, ilab = random.meta$n, ilab.xpos = -6)
text(c(-6), 10.5, c("n"))
title("Forest Plot: CD000561")

```
  
  In the forest plot above, the question is: Do tricyclic antidepressants help elderly people who are depressed? The authors of the review identified 9 studies that examine tricyclic antidepressents. The forest plot displays the name, sample size, and study-level effect measures. For this review, the study level estimates are log odds ratios of being depressed. Log odds ratios are converted to odds ratios through exponentiating the estimate. For example, the Georgotas 1986 reports a log odds ratio of -2.53. exp(-2.53) = .08. In other words, the odds of staying depressed for people who were taking tricyclic antidepressants were  .08 times the odds of people who were taking the placebo (92% reduction in the odds of being depressed).
  
&nbsp;
  
  An odds ratio of .08 strongly favors the tricyclic antidepressant treatment. However, it is clear in the forest plot that this is the most extreme treatment effect estimate. The Georgotas study's sample size is only 52. It may be because of random chance that the treatment is so effective. In the forest plot above, 6 of the 9 studies' confidence intervals cross the zero line (which represents an odds ratio of 1). Because the zero line represents the null hypothesis, these 6 studies are thus not statistically significant at the .05 level. One of the takeaway messages from examing the forest plot is that simply looking at statistical significance of individual studies is not sufficient for summarizing evidence. In this case, all of the studies favor the treatment. If the individual studies are underpowered, a clinically important effect may be missed if the relevant data is not aggregated.
  
&nbsp;
  
  The diamond at the bottom of the forest plot represents the meta-analysis estimate and confidence interval. Here, the estimate comes from a fixed effect model. In this example, the meta-analysis estimate is -1.15, which corresponds to an odds ratio of exp(-1.15) = .316 (the treatment is associated with a 68% reduction in the odds of being dpressed). The meta-analysis treatment effect estimate is statistically significant. The confidence interval of the estimate (the width of the diamond in the forest plot) is smaller than any of the individual studies. In other words, the aggregate estimate is more precise. 
  
&nbsp;

  The meta-analysis estimate is a weighted mean of the individual study estimates. In the forest plot above, the relative weight given to each individual study in the calculation of the aggregate estimate is represented by the size of the square. How are these weights calcuated?
  
# Fixed Effect vs Random Effects 

## Fixed Effects Models

  The weighting schemes come in two flavors: fixed effect models and random effects models. The fixed effect model assumes that all of the studies share a common effect. For example, suppose a college wants to know the average math aptitude score of its students. Due to budget, time or space constraints, the school cannot expect to administer the math test to the entire college. Instead, they administer the test to five random samples of students. Each of the testing sessions is considered to be a "study."
  
&nbsp;

  Assuming each of the testing session were similar, it makes sense to think that each of the “studies” is a random sample from a common population (all the students at the college). In this case, the weighted average is a relatively straightforward calculation: the studies with more precision (lower variance) get higher weight. Since sample size is the primary driver for precision, studies with higher sample sizes get more weight. Here is the idea expressed mathematically:
  
$$ \theta_{FE} = \dfrac{\sum{w_{iFE}}*y_i}{\sum{w_{iFE}}}, w_{iFE} = 1 / v_i   $$

The fixed effect meta-analysis estimate of the effect size, $\theta_{FE}$, is equal to the weighted mean of the individual study estimates, $y_i$. The weights for the fixed effect model are $1/v_i$, where $v_i$ is the variance of the individual study estimate. As the variance of a study estimate increases, the weight it it given in the summary effect calculation decreases.  



## Random Effects Models

  
  
  
  
  
  

# Data and Data Cleaning

The raw data for this analysis was extracted from The Cochrane Database of Systematic Reviews (CDSR). The CDSR contains peer-reviewed and high quality healthcare systematic reviews conducted by Cochrane Review groups. The data contain all reviews with binary outcomes from 2003 to 2010. 


Since tests for heterogeneity lack power, meta-analyses with less than 5 studies were filtered out. Only 1 meta-analysis per review is used to estimate heterogeneity in order to avoid concerns about the correlation in heterogeneity estimates from each meta-analysis within a review. The meta-analysis with the highest number of studies is selected per each review. In the event of a tie, the meta-analysis with the highest total sample size is selected. If there is still a tie, the meta-analysis is selected at random. Studies that had rare events (defined as only one occurrence) are excluded because inverse-variance methods are biased for rarer outcomes. Also, studies with 0 values in their control and treatment arms are excluded because it makes calculating the summary effect impossible. 


Overall, the cleaned data contains analyses from 1,415 reviews. The smallest meta sample is 93 and the largest is 3,231,551. The highest number of studies used in an analysis is 489. 


# Exploritory Analysis



```{r}
n.studies.hist
```

```{r}
meta.n.density.plot
```


# Analysis

```{r, results = 'asis'}
stargazer(sums4, header = FALSE,
          summary = FALSE, table.placement = 'H')
```

```{r}
tau.square.density.plot
```

```{r}
tau.se.density.plot
```

```{r, fig.height=8, fig.width=12}
tau.estimates.plot
```

```{r, fig.height=8, fig.width=12}
summary.estimates.plot
```


```{r}
p.diff.plot
```


```{r}

test = full %>%
  gather(key = "mod", value = "taus", DL.tau2, PM.tau2,
         HE.tau2, HS.tau2, ML.tau2, REML.tau2, SJ.tau2) %>%
  group_by(my_ID, mod) %>%
  slice(1) %>%
  ungroup()

test1 = test %>%
  group_by(my_ID) %>%
  mutate(differ = max(taus) - min(taus)) %>%
  slice(1)

test2 = lm(differ ~ log(meta.n), data = test1)
summary(test2)
```


